# Ocena rzetelnoÅ›ci artykuÅ‚Ã³w (Fake News) â€“ regresja i interpretacja

Projekt wykorzystujÄ…cy dataset FakeHealth do przewidywania rzetelnoÅ›ci artykuÅ‚Ã³w zdrowotnych za pomocÄ… regresji i interpretacji modeli ML.

## ğŸ“Š Dataset

**FakeHealth** to zbiÃ³r danych zawierajÄ…cy:
- **HealthStory**: ~1638 artykuÅ‚Ã³w z rÃ³Å¼nych ÅºrÃ³deÅ‚ medialnych
- **HealthRelease**: ~599 komunikatÃ³w prasowych uniwersytetÃ³w

KaÅ¼dy artykuÅ‚ zawiera:
- PeÅ‚ny tekst artykuÅ‚u
- ProfesjonalnÄ… recenzjÄ™ z ocenami rzetelnoÅ›ci (rating 1-5)
- 10 kryteriÃ³w oceny jakoÅ›ci dziennikarstwa medycznego
- SzczegÃ³Å‚owe wyjaÅ›nienia ocen

**Å¹rÃ³dÅ‚o**: [FakeHealth Repository](https://github.com/EnyanDai/FakeHealth)  
**Paper**: [Ginger Cannot Cure Cancer: Battling Fake Health News](https://arxiv.org/abs/2002.00837)

---

## ğŸš€ Szybki start

### Krok 1: Instalacja zaleÅ¼noÅ›ci

```bash
pip install -r requirements.txt
```

Minimalne wymagania:
```bash
pip install pandas numpy scikit-learn matplotlib seaborn
```

### Krok 2: Przygotowanie danych

```bash
python prepare_data.py
```

Skrypt automatycznie:
- Wczyta wszystkie artykuÅ‚y z folderÃ³w `dataset/content/HealthStory` i `dataset/content/HealthRelease`
- PoÅ‚Ä…czy je z recenzjami z `dataset/reviews/`
- Utworzy 4 pliki wynikowe:
  - `HealthStory_combined.json` - peÅ‚ne dane HealthStory (z kryteriami)
  - `HealthStory_combined.csv` - uproszczona wersja CSV
  - `HealthRelease_combined.json` - peÅ‚ne dane HealthRelease
  - `HealthRelease_combined.csv` - uproszczona wersja CSV

### Krok 3: Uruchomienie przykÅ‚adowej analizy

```bash
python test_analysis.py
```

---

## ğŸ“ Struktura projektu

```
.
â”œâ”€â”€ dataset/                    # Oryginalne dane FakeHealth
â”‚   â”œâ”€â”€ content/
â”‚   â”‚   â”œâ”€â”€ HealthStory/       # ~1638 artykuÅ‚Ã³w (pliki JSON)
â”‚   â”‚   â””â”€â”€ HealthRelease/     # ~599 artykuÅ‚Ã³w (pliki JSON)
â”‚   â””â”€â”€ reviews/
â”‚       â”œâ”€â”€ HealthStory.json   # Recenzje dla HealthStory
â”‚       â””â”€â”€ HealthRelease.json # Recenzje dla HealthRelease
â”‚
â”œâ”€â”€ prepare_data.py            # Skrypt Å‚Ä…czÄ…cy content + reviews
â”œâ”€â”€ test_analysis.py     # PrzykÅ‚adowa analiza i modele ML
â”œâ”€â”€ requirements.txt           # Wymagane biblioteki
â””â”€â”€ README.md                  # Ten plik
```

---

## ğŸ” Struktura danych wynikowych

Po uruchomieniu `prepare_data.py` kaÅ¼dy rekord w plikach `*_combined.json` zawiera:

### Dane z artykuÅ‚u:
- `news_id` - unikalny identyfikator
- `url` - adres URL artykuÅ‚u
- `title` - tytuÅ‚ artykuÅ‚u
- `text` - **peÅ‚ny tekst artykuÅ‚u** (do analizy NLP)
- `authors` - lista autorÃ³w
- `publish_date` - data publikacji (timestamp)
- `keywords` - sÅ‚owa kluczowe
- `source` - ÅºrÃ³dÅ‚o artykuÅ‚u

### Dane z recenzji:
- `rating` - **ocena rzetelnoÅ›ci (1-5)** - zmienna celu do regresji! â­
  - 1 = najgorszy (fake news)
  - 5 = najlepszy (rzetelny)
- `review_title` - tytuÅ‚ recenzji
- `description` - krÃ³tki opis problemu z artykuÅ‚em
- `reviewers` - lista recenzentÃ³w
- `category` - kategoria ÅºrÃ³dÅ‚a (np. "The Guardian", "University news release")
- `tags` - tagi tematyczne
- `review_summary` - podsumowanie recenzji
- `why_this_matters` - dlaczego to ma znaczenie

### Kryteria oceny (do interpretacji modelu):
- `criteria` - lista 10 kryteriÃ³w, kaÅ¼de zawiera:
  - `question` - pytanie (np. "Czy artykuÅ‚ omawia koszty?")
  - `answer` - odpowiedÅº: "Satisfactory" / "Not Satisfactory" / "Not Applicable"
  - `explanation` - szczegÃ³Å‚owe wyjaÅ›nienie oceny
  
- `num_satisfactory` - liczba speÅ‚nionych kryteriÃ³w
- `num_not_satisfactory` - liczba niespeÅ‚nionych kryteriÃ³w
- `num_not_applicable` - liczba kryteriÃ³w nieaplikowalnych

### 10 kryteriÃ³w oceny jakoÅ›ci dziennikarstwa medycznego:
1. Czy artykuÅ‚ omawia **koszty** interwencji?
2. Czy **kwantyfikuje korzyÅ›ci**?
3. Czy omawia **zagroÅ¼enia/skutki uboczne**?
4. Czy ocenia **jakoÅ›Ä‡ dowodÃ³w naukowych**?
5. Czy nie przesadza z chorobÄ… (**disease-mongering**)?
6. Czy uÅ¼ywa **niezaleÅ¼nych ÅºrÃ³deÅ‚**?
7. Czy **porÃ³wnuje z alternatywami**?
8. Czy ustala **dostÄ™pnoÅ›Ä‡** interwencji?
9. Czy wspomina o **nowoÅ›ci vs. faktycznej innowacji**?
10. Czy identyfikuje **konflikty interesÃ³w**?

---

## ğŸ¯ Cel projektu

### Problem
Przewidywanie **ratingu rzetelnoÅ›ci** artykuÅ‚u (1-5) na podstawie jego tekstu:
- **Rating 1-2**: Fake news / wprowadzajÄ…cy w bÅ‚Ä…d
- **Rating 3**: Mieszane / czÄ™Å›ciowo rzetelny
- **Rating 4-5**: Rzetelny / wysokiej jakoÅ›ci

### PodejÅ›cie
1. **Regresja**: Przewidywanie ciÄ…gÅ‚ej wartoÅ›ci ratingu (1-5)
2. **Interpretacja**: Zrozumienie, jakie cechy tekstu wskazujÄ… na fake news

---

## ğŸ’» PrzykÅ‚ad uÅ¼ycia w Python

```python
import json
import pandas as pd

# Wczytanie danych
with open('HealthStory_combined.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

# Lub wersja CSV (bez zagnieÅ¼dÅ¼onych struktur)
df = pd.read_csv('HealthStory_combined.csv', encoding='utf-8-sig')

# Podstawowe statystyki
print(f"Liczba artykuÅ‚Ã³w: {len(df)}")
print(f"\nRozkÅ‚ad ratingÃ³w:")
print(df['rating'].value_counts().sort_index())

# Analiza tekstu
print(f"\nÅšrednia dÅ‚ugoÅ›Ä‡ tekstu: {df['text'].str.len().mean():.0f} znakÃ³w")

# Korelacja miÄ™dzy kryteriami a ratingiem
print(f"\nKorelacja z ratingiem:")
print(df[['num_satisfactory', 'num_not_satisfactory', 'rating']].corr())
```

---

## ğŸ”¬ PrzykÅ‚adowe modele

### Model 1: Regresja Liniowa z TF-IDF
- **Reprezentacja tekstu**: TF-IDF (1000 najwaÅ¼niejszych sÅ‚Ã³w/bigramÃ³w)
- **Model**: Regresja liniowa
- **Interpretacja**: WspÃ³Å‚czynniki pokazujÄ… wpÅ‚yw sÅ‚Ã³w na rating
  - SÅ‚owa z pozytywnymi wspÃ³Å‚czynnikami â†’ wskazujÄ… na rzetelnoÅ›Ä‡
  - SÅ‚owa z negatywnymi wspÃ³Å‚czynnikami â†’ wskazujÄ… na fake news

### Model 2: Random Forest
- **Reprezentacja**: TF-IDF
- **Model**: Random Forest Regressor
- **Interpretacja**: Feature importance - najwaÅ¼niejsze sÅ‚owa/frazy

---

## ğŸ“Š MoÅ¼liwe analizy dla projektu

### 1. Regresja - przewidywanie ratingu
- **Zmienne objaÅ›niajÄ…ce**: 
  - Tekst artykuÅ‚u (gÅ‚Ã³wna zmienna)
  - TytuÅ‚
  - SÅ‚owa kluczowe
  - DÅ‚ugoÅ›Ä‡ tekstu
  - Å¹rÃ³dÅ‚o/kategoria
- **Zmienna celu**: `rating` (1-5)
- **Metody**: 
  - Regresja liniowa z TF-IDF âœ…
  - Random Forest Regressor âœ…
  - XGBoost / LightGBM
  - Regresja z embeddings (Word2Vec, BERT)
  - Sieci neuronowe (LSTM, CNN)

### 2. Interpretacja modelu
- **SHAP values** - ktÃ³re sÅ‚owa/frazy wpÅ‚ywajÄ… na ocenÄ™ konkretnego artykuÅ‚u
- **LIME** - lokalne wyjaÅ›nienia predykcji
- **Analiza wspÃ³Å‚czynnikÃ³w** regresji liniowej
- **Feature importance** z tree-based models
- **Attention mechanisms** (dla deep learning)

### 3. Feature Engineering
- DÅ‚ugoÅ›Ä‡ tekstu, liczba zdaÅ„, zÅ‚oÅ¼onoÅ›Ä‡ skÅ‚adniowa
- Analiza sentymentu
- Wykrywanie clickbait w tytuÅ‚ach
- Å¹rÃ³dÅ‚o artykuÅ‚u jako cecha kategoryczna
- **Wykorzystanie kryteriÃ³w** jako dodatkowych features

### 4. Dodatkowe zadania
- **Klasyfikacja binarna**: rating â‰¤ 2 (fake) vs rating â‰¥ 4 (rzetelny)
- **Multi-class classification**: 1, 2, 3, 4, 5 jako osobne klasy
- **Topic modeling** (LDA) - tematy fake vs rzetelnych artykuÅ‚Ã³w
- **Multi-task learning**: przewidywanie ratingu + wszystkich 10 kryteriÃ³w jednoczeÅ›nie

### 5. Wykorzystanie kryteriÃ³w oceny
Kryteria mogÄ… byÄ‡ uÅ¼yte do:
- **Walidacji modelu** - czy model wykrywa te same problemy co recenzenci?
- **Feature engineering** - dodatkowe zmienne objaÅ›niajÄ…ce
- **Multi-task learning** - przewidywanie ratingu + kryteriÃ³w jednoczeÅ›nie
- **Interpretacji** - ktÃ³re kryteria sÄ… najwaÅ¼niejsze dla ratingu?

---

## ğŸ“ˆ Metryki oceny

- **RÂ² Score**: JakoÅ›Ä‡ dopasowania modelu (0-1, wyÅ¼szy = lepszy)
- **RMSE**: Root Mean Squared Error (niÅ¼szy = lepszy)
- **MAE**: Mean Absolute Error - Å›redni bÅ‚Ä…d w punktach ratingu (niÅ¼szy = lepszy)

### PrzykÅ‚adowe wyniki dla modeli bazowych:
- **Regresja Liniowa**: RÂ² ~0.30-0.40, MAE ~0.6-0.8
- **Random Forest**: RÂ² ~0.35-0.50, MAE ~0.5-0.7

---

## ğŸ’¡ MoÅ¼liwoÅ›ci rozwoju projektu

### 1. Lepsze reprezentacje tekstu
- **Word2Vec / GloVe** embeddings
- **BERT / transformers** (state-of-the-art dla NLP)
- **Doc2Vec** dla caÅ‚ych dokumentÃ³w
- **FastText** z subword information

### 2. Zaawansowane modele
- **XGBoost / LightGBM** - gradient boosting
- **Sieci neuronowe**: LSTM, CNN dla tekstu, Transformers
- **Ensemble methods** - Å‚Ä…czenie predykcji kilku modeli
- **Stacking** - wielopoziomowe modele

### 3. Cross-dataset learning
- Trening na HealthStory, test na HealthRelease (i odwrotnie)
- **Transfer learning** miÄ™dzy datasetami
- Analiza, co rÃ³Å¼ni te dwa datasety

### 4. Interpretacja i wyjaÅ›nialnoÅ›Ä‡
- **SHAP values** dla kaÅ¼dej predykcji
- **LIME** dla lokalnych wyjaÅ›nieÅ„
- **Attention visualization** (dla modeli z attention)
- Analiza, ktÃ³re frazy sÄ… najwaÅ¼niejsze

---

## âš ï¸ Uwagi i ograniczenia

### Ograniczenia datasetu:
- Rating jest **subiektywny** (ocena ekspertÃ³w), ale konsystentny
- Dataset jest **niezbalansowany** - wiÄ™cej artykuÅ‚Ã³w z niskim ratingiem
- **JÄ™zyk angielski** - modele mogÄ… nie dziaÅ‚aÄ‡ dla innych jÄ™zykÃ³w
- **Rozmiar** - ~2200 artykuÅ‚Ã³w (nie jest bardzo duÅ¼y dla deep learning)

### Statystyki datasetu:

**HealthStory** (~1638 artykuÅ‚Ã³w):
- ArtykuÅ‚y z rÃ³Å¼nych ÅºrÃ³deÅ‚ medialnych (gazety, portale)
- Recenzje profesjonalne z HealthNewsReview.org
- WiÄ™ksza rÃ³Å¼norodnoÅ›Ä‡ ÅºrÃ³deÅ‚ i stylÃ³w

**HealthRelease** (~599 artykuÅ‚Ã³w):
- GÅ‚Ã³wnie komunikaty prasowe uniwersytetÃ³w
- Bardziej homogenna grupa
- CzÄ™sto bardziej "marketingowe" podejÅ›cie

---

## ğŸ“š Literatura i ÅºrÃ³dÅ‚a

- [FakeHealth Paper (arXiv)](https://arxiv.org/abs/2002.00837) - Opis datasetu i metodologii
- [HealthNewsReview.org](https://www.healthnewsreview.org/) - Å¹rÃ³dÅ‚o recenzji i kryteriÃ³w
- [Scikit-learn Documentation](https://scikit-learn.org/) - Machine learning w Python
- [SHAP Documentation](https://shap.readthedocs.io/) - Interpretacja modeli
- [LIME Documentation](https://lime-ml.readthedocs.io/) - Lokalne wyjaÅ›nienia

---

## ğŸ“ WskazÃ³wki do raportu/prezentacji

Warto uwzglÄ™dniÄ‡ w projekcie:

1. **Eksploracja danych** (EDA):
   - RozkÅ‚ad ratingÃ³w (histogram, statystyki)
   - DÅ‚ugoÅ›Ä‡ tekstÃ³w i jej korelacja z ratingiem
   - Korelacja miÄ™dzy kryteriami a ratingiem
   - NajczÄ™stsze sÅ‚owa w fake news vs rzetelnych artykuÅ‚ach

2. **Preprocessing i feature engineering**:
   - TF-IDF vectorization (parametry, uzasadnienie)
   - Normalizacja danych
   - PodziaÅ‚ train/test/validation
   - Dodatkowe features (dÅ‚ugoÅ›Ä‡, sentiment, itp.)

3. **Modele**:
   - Co najmniej **2-3 rÃ³Å¼ne podejÅ›cia**
   - Uzasadnienie wyboru modeli
   - Tuning hiperparametrÃ³w (grid search, cross-validation)

4. **Wyniki**:
   - **Tabele** z metrykami (RÂ², RMSE, MAE) dla wszystkich modeli
   - **Wykresy**: predykcja vs rzeczywistoÅ›Ä‡, feature importance, itp.
   - PorÃ³wnanie modeli
   - Analiza bÅ‚Ä™dÃ³w (ktÃ³re artykuÅ‚y sÄ… Åºle klasyfikowane?)

5. **Interpretacja** (kluczowe!):
   - Jakie **sÅ‚owa/frazy** wskazujÄ… na fake news?
   - Jakie **sÅ‚owa/frazy** wskazujÄ… na rzetelnoÅ›Ä‡?
   - Czy model nauczyÅ‚ siÄ™ rozpoznawaÄ‡ **kryteria jakoÅ›ci**?
   - PrzykÅ‚ady konkretnych predykcji z wyjaÅ›nieniami

6. **Wnioski**:
   - Co model nauczyÅ‚ siÄ™ rozpoznawaÄ‡?
   - Czy wyniki majÄ… sens z punktu widzenia dziennikarstwa?
   - Ograniczenia podejÅ›cia
   - MoÅ¼liwe zastosowania praktyczne

7. **Ograniczenia i future work**:
   - Dataset size, jÄ™zyk, subiektywnoÅ›Ä‡ ocen
   - MoÅ¼liwe ulepszenia (BERT, wiÄ™cej danych, itp.)
   - Transfer learning na inne domeny
